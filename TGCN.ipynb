{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "783ba4db-c538-465f-a45c-0ee2975feaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Data Info =====\n",
      "BERT train: (6405, 64, 768)\n",
      "BERT test : (1602, 64, 768)\n",
      "\n",
      "Train seq: torch.Size([5756, 10, 64, 768]), Val seq: torch.Size([631, 10, 64, 768]), Test seq: torch.Size([1593, 10, 64, 768])\n",
      "Epoch 01/10 | Loss: 0.6150 | Val F1: 0.6824\n",
      "Epoch 02/10 | Loss: 0.5574 | Val F1: 0.6612\n",
      "Epoch 03/10 | Loss: 0.5077 | Val F1: 0.6699\n",
      "Epoch 04/10 | Loss: 0.4453 | Val F1: 0.6805\n",
      "Epoch 05/10 | Loss: 0.3760 | Val F1: 0.6994\n",
      "Epoch 06/10 | Loss: 0.3013 | Val F1: 0.7072\n",
      "Epoch 07/10 | Loss: 0.2374 | Val F1: 0.7011\n",
      "Epoch 08/10 | Loss: 0.1928 | Val F1: 0.7380\n",
      "Epoch 09/10 | Loss: 0.1750 | Val F1: 0.7061\n",
      "Epoch 10/10 | Loss: 0.1394 | Val F1: 0.7240\n",
      "\n",
      "===== Final Test Evaluation =====\n",
      "Accuracy : 0.7433\n",
      "Precision: 0.7117\n",
      "Recall   : 0.7456\n",
      "F1 Score : 0.7282\n",
      "Confusion Matrix:\n",
      " [[636 222]\n",
      " [187 548]]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Temporal Graph Convolutional Network (TGCN)\n",
    "# Depression Detection using BERT embeddings  \n",
    " \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 1. Load BERT embeddings\n",
    "# --------------------------------- \n",
    "INPUT_DIR = \"\"  \n",
    "\n",
    "bert_train = np.load(os.path.join(INPUT_DIR, \"BERT_X_train_emb.npy\"))\n",
    "bert_test  = np.load(os.path.join(INPUT_DIR, \"BERT_X_test_emb.npy\"))\n",
    "y_train = np.load(os.path.join(INPUT_DIR, \"BERT_y_train.npy\"))\n",
    "y_test  = np.load(os.path.join(INPUT_DIR, \"BERT_y_test.npy\"))\n",
    "\n",
    "print(\"\\n===== Data Info =====\")\n",
    "print(f\"BERT train: {bert_train.shape}\")\n",
    "print(f\"BERT test : {bert_test.shape}\")\n",
    "\n",
    "# Convert to torch tensors\n",
    "x_train = torch.from_numpy(bert_train.astype(np.float32))\n",
    "x_test  = torch.from_numpy(bert_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.int64))\n",
    "y_test  = torch.from_numpy(y_test.astype(np.int64))\n",
    "\n",
    "# Create validation split (10% of training)\n",
    "val_size = int(0.1 * len(x_train))\n",
    "x_val, y_val = x_train[-val_size:], y_train[-val_size:]\n",
    "x_train, y_train = x_train[:-val_size], y_train[:-val_size]\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 2. Create temporal sliding windows\n",
    "# ----------------------------- \n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "def make_sequences(x_all, y_all, window=WINDOW_SIZE):\n",
    "    seqs, labels = [], []\n",
    "    for i in range(len(x_all) - window + 1):\n",
    "        seqs.append(x_all[i:i+window])       \n",
    "        labels.append(y_all[i+window-1])    \n",
    "    return torch.stack(seqs), torch.stack(labels)\n",
    "\n",
    "train_seq, train_y = make_sequences(x_train, y_train)\n",
    "val_seq, val_y     = make_sequences(x_val, y_val)\n",
    "test_seq, test_y   = make_sequences(x_test, y_test)\n",
    "\n",
    "print(f\"\\nTrain seq: {train_seq.shape}, Val seq: {val_seq.shape}, Test seq: {test_seq.shape}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 3. TemporalGCN model (auto node detection)\n",
    "# ----------------------------------------------------------\n",
    "class TemporalGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, window_size, n_nodes=None):\n",
    "        super().__init__()\n",
    "        self.gcn = GCNConv(in_channels, hidden_channels)\n",
    "        self.gru = nn.GRU(hidden_channels, hidden_channels, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_channels, out_channels)\n",
    "        self.window_size = window_size\n",
    "        self.n_nodes = n_nodes\n",
    "        self.edge_nodes = None   \n",
    "\n",
    "    def _build_edges(self, n_nodes, device):\n",
    "        src = torch.arange(n_nodes - 1)\n",
    "        dst = torch.arange(1, n_nodes)\n",
    "        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])]).to(device)\n",
    "        return edge_index\n",
    "\n",
    "    def forward(self, x_seq):\n",
    "        \"\"\"\n",
    "        x_seq: [B, W, N, F]\n",
    "        - GCN operates on N nodes per timestep\n",
    "        - GRU models temporal sequence across W steps\n",
    "        \"\"\"\n",
    "        B, W, N, Fdim = x_seq.shape\n",
    "        device = x_seq.device\n",
    "\n",
    "        # Build edges dynamically if needed\n",
    "        if (self.edge_nodes is None) or (self.n_nodes != N):\n",
    "            self.n_nodes = N\n",
    "            self.edge_nodes = self._build_edges(N, device)\n",
    "\n",
    "        outputs = []\n",
    "        for b in range(B):\n",
    "            temporal_feats = []\n",
    "            for t in range(W):\n",
    "                h_nodes = F.relu(self.gcn(x_seq[b, t], self.edge_nodes))   \n",
    "                h_mean = h_nodes.mean(dim=0)   \n",
    "                temporal_feats.append(h_mean.unsqueeze(0))\n",
    "            temporal_feats = torch.cat(temporal_feats, dim=0).unsqueeze(0)   \n",
    "            _, h_n = self.gru(temporal_feats)   \n",
    "            out = self.fc(h_n.squeeze(0).squeeze(0))\n",
    "            outputs.append(out)\n",
    "        return torch.stack(outputs, dim=0)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 4. Training setup \n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IN_DIM = bert_train.shape[2]   # 768\n",
    "\n",
    "model = TemporalGCN(\n",
    "    in_channels=IN_DIM,\n",
    "    hidden_channels=128,\n",
    "    out_channels=2,\n",
    "    window_size=WINDOW_SIZE\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "def batched_iter(X, y, batch_size=8):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        yield X[i:i+batch_size], y[i:i+batch_size]\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 5. Train loop\n",
    "# ---------------- \n",
    "EPOCHS = 10\n",
    "best_val_f1 = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in batched_iter(train_seq, train_y):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = F.cross_entropy(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(xb)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in batched_iter(val_seq, val_y):\n",
    "            logits = model(xb.to(device))\n",
    "            preds.append(logits.argmax(dim=1).cpu())\n",
    "    val_pred = torch.cat(preds)\n",
    "    val_acc = accuracy_score(val_y, val_pred)\n",
    "    _, _, val_f1, _ = precision_recall_fscore_support(val_y, val_pred, average=\"binary\")\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_state = model.state_dict()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} | Loss: {total_loss/len(train_seq):.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "# ----------------------------- ------------ \n",
    "# Step 6. Final testing\n",
    "# ----------------------------------- \n",
    "model.load_state_dict(best_state)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = []\n",
    "    for xb, yb in batched_iter(test_seq, test_y):\n",
    "        logits = model(xb.to(device))\n",
    "        preds.append(logits.argmax(dim=1).cpu())\n",
    "    y_pred = torch.cat(preds)\n",
    "    y_true = test_y\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\")\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\n===== Final Test Evaluation =====\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e49b944a-2e0f-4276-9554-2eecee9f28ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Data Info =====\n",
      "T5 train: (6405, 64, 768)\n",
      "T5 test : (1602, 64, 768)\n",
      "\n",
      "Train seq: torch.Size([5756, 10, 64, 768]), Val seq: torch.Size([631, 10, 64, 768]), Test seq: torch.Size([1593, 10, 64, 768])\n",
      "Epoch 01/10 | Loss: 0.6202 | Val F1: 0.6615\n",
      "Epoch 02/10 | Loss: 0.5440 | Val F1: 0.6826\n",
      "Epoch 03/10 | Loss: 0.4696 | Val F1: 0.7158\n",
      "Epoch 04/10 | Loss: 0.3877 | Val F1: 0.7172\n",
      "Epoch 05/10 | Loss: 0.3074 | Val F1: 0.7249\n",
      "Epoch 06/10 | Loss: 0.2270 | Val F1: 0.7474\n",
      "Epoch 07/10 | Loss: 0.1875 | Val F1: 0.7561\n",
      "Epoch 08/10 | Loss: 0.1599 | Val F1: 0.7710\n",
      "Epoch 09/10 | Loss: 0.1078 | Val F1: 0.7752\n",
      "Epoch 10/10 | Loss: 0.1067 | Val F1: 0.7690\n",
      "\n",
      "===== Final Test Evaluation =====\n",
      "Accuracy : 0.7784\n",
      "Precision: 0.7553\n",
      "Recall   : 0.7687\n",
      "F1 Score : 0.7620\n",
      "Confusion Matrix:\n",
      " [[675 183]\n",
      " [170 565]]\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Temporal Graph Convolutional Network (TGCN)\n",
    "# Depression Detection using T5 embeddings  \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------------- -\n",
    "# Step 1. Load T5 embeddings\n",
    "# -------------------------------------------------- \n",
    "INPUT_DIR = \"\"  \n",
    "\n",
    "t5_train = np.load(os.path.join(INPUT_DIR, \"T5_X_train_emb.npy\"))\n",
    "t5_test  = np.load(os.path.join(INPUT_DIR, \"T5_X_test_emb.npy\"))\n",
    "y_train  = np.load(os.path.join(INPUT_DIR, \"BERT_y_train.npy\"))\n",
    "y_test   = np.load(os.path.join(INPUT_DIR, \"BERT_y_test.npy\"))\n",
    "\n",
    "print(\"\\n===== Data Info =====\")\n",
    "print(f\"T5 train: {t5_train.shape}\")\n",
    "print(f\"T5 test : {t5_test.shape}\")\n",
    "\n",
    "# Convert to torch tensors\n",
    "x_train = torch.from_numpy(t5_train.astype(np.float32))\n",
    "x_test  = torch.from_numpy(t5_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.int64))\n",
    "y_test  = torch.from_numpy(y_test.astype(np.int64))\n",
    "\n",
    "# Create validation split (10%)\n",
    "val_size = int(0.1 * len(x_train))\n",
    "x_val, y_val = x_train[-val_size:], y_train[-val_size:]\n",
    "x_train, y_train = x_train[:-val_size], y_train[:-val_size]\n",
    "\n",
    "# ----------------------------- \n",
    "# Step 2. Create temporal sliding windows\n",
    "# ------------------------------------------- \n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "def make_sequences(x_all, y_all, window=WINDOW_SIZE):\n",
    "    seqs, labels = [], []\n",
    "    for i in range(len(x_all) - window + 1):\n",
    "        seqs.append(x_all[i:i+window])       \n",
    "        labels.append(y_all[i+window-1])    \n",
    "    return torch.stack(seqs), torch.stack(labels)\n",
    "\n",
    "train_seq, train_y = make_sequences(x_train, y_train)\n",
    "val_seq, val_y     = make_sequences(x_val, y_val)\n",
    "test_seq, test_y   = make_sequences(x_test, y_test)\n",
    "\n",
    "print(f\"\\nTrain seq: {train_seq.shape}, Val seq: {val_seq.shape}, Test seq: {test_seq.shape}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 3. TemporalGCN model (auto node detection \n",
    "\n",
    "\n",
    "class TemporalGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, window_size, n_nodes=None):\n",
    "        super().__init__()\n",
    "        self.gcn = GCNConv(in_channels, hidden_channels)\n",
    "        self.gru = nn.GRU(hidden_channels, hidden_channels, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_channels, out_channels)\n",
    "        self.window_size = window_size\n",
    "        self.n_nodes = n_nodes\n",
    "        self.edge_nodes = None   \n",
    "\n",
    "    def _build_edges(self, n_nodes, device):\n",
    "        src = torch.arange(n_nodes - 1)\n",
    "        dst = torch.arange(1, n_nodes)\n",
    "        edge_index = torch.stack([torch.cat([src, dst]), torch.cat([dst, src])]).to(device)\n",
    "        return edge_index\n",
    "\n",
    "    def forward(self, x_seq):\n",
    "        \"\"\"\n",
    "        x_seq: [B, W, N, F]\n",
    "        - GCN operates on N nodes per timestep\n",
    "        - GRU models temporal sequence across W steps\n",
    "        \"\"\"\n",
    "        B, W, N, Fdim = x_seq.shape\n",
    "        device = x_seq.device\n",
    "\n",
    "        # Build edges dynamically if needed\n",
    "        if (self.edge_nodes is None) or (self.n_nodes != N):\n",
    "            self.n_nodes = N\n",
    "            self.edge_nodes = self._build_edges(N, device)\n",
    "\n",
    "        outputs = []\n",
    "        for b in range(B):\n",
    "            temporal_feats = []\n",
    "            for t in range(W):\n",
    "                h_nodes = F.relu(self.gcn(x_seq[b, t], self.edge_nodes))   \n",
    "                h_mean = h_nodes.mean(dim=0)   \n",
    "                temporal_feats.append(h_mean.unsqueeze(0))\n",
    "            temporal_feats = torch.cat(temporal_feats, dim=0).unsqueeze(0)   \n",
    "            _, h_n = self.gru(temporal_feats)   \n",
    "            out = self.fc(h_n.squeeze(0).squeeze(0))\n",
    "            outputs.append(out)\n",
    "        return torch.stack(outputs, dim=0)\n",
    "\n",
    "# --------------------------- \n",
    "# Step 4. Training setup\n",
    "# ------------------------- \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IN_DIM = t5_train.shape[2]   # should be 768\n",
    "\n",
    "model = TemporalGCN(\n",
    "    in_channels=IN_DIM,\n",
    "    hidden_channels=128,\n",
    "    out_channels=2,\n",
    "    window_size=WINDOW_SIZE\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "def batched_iter(X, y, batch_size=8):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        yield X[i:i+batch_size], y[i:i+batch_size]\n",
    "\n",
    "# -------------------------------------- \n",
    "# Step 5. Training loop\n",
    "# -------------------- \n",
    "EPOCHS = 10\n",
    "best_val_f1 = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in batched_iter(train_seq, train_y):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = F.cross_entropy(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(xb)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in batched_iter(val_seq, val_y):\n",
    "            logits = model(xb.to(device))\n",
    "            preds.append(logits.argmax(dim=1).cpu())\n",
    "    val_pred = torch.cat(preds)\n",
    "    val_acc = accuracy_score(val_y, val_pred)\n",
    "    _, _, val_f1, _ = precision_recall_fscore_support(val_y, val_pred, average=\"binary\")\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_state = model.state_dict()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} | Loss: {total_loss/len(train_seq):.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "# --------------------------------- \n",
    "# Step 6. Final testing\n",
    "# ------------------------------ \n",
    "model.load_state_dict(best_state)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = []\n",
    "    for xb, yb in batched_iter(test_seq, test_y):\n",
    "        logits = model(xb.to(device))\n",
    "        preds.append(logits.argmax(dim=1).cpu())\n",
    "    y_pred = torch.cat(preds)\n",
    "    y_true = test_y\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\")\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\n===== Final Test Evaluation =====\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad148de-8e63-4cfa-b3e3-48944e4c6f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
